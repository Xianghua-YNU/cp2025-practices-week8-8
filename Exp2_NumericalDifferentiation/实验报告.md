# 实验二：数值微分的误差权衡

## 1. 实验目的
- 理解数值微分中截断误差与舍入误差的权衡关系
- 观察有限差分法计算导数时的误差变化规律
- 分析步长对数值微分精度的影响
- 确定最优步长范围

## 2. 实验方法
### 2.1 理论基础
数值微分是通过有限差分近似导数的计算方法。本实验实现了两种差分方法：
- 前向差分法: $f'(x) \approx \frac{f(x+\delta) - f(x)}{\delta}$
- 中心差分法: $f'(x) \approx \frac{f(x+\delta) - f(x-\delta)}{2\delta}$

### 2.2 测试函数
本实验使用函数 $f(x) = x(x-1)$，其解析导数为 $f'(x) = 2x - 1$。

### 2.3 实验步骤
1. 实现前向差分和中心差分函数
2. 在 $x=1$ 点计算不同步长下的数值导数
3. 计算数值导数与解析导数的相对误差
4. 绘制误差-步长关系图（对数坐标）
5. 分析最优步长和收敛阶数

## 3. 实验结果
### 3.1 数据表格
| 步长(δ) | 前向差分值 | 中心差分值 | 解析解 | 前向差分相对误差 | 中心差分相对误差 |
|---------|------------|------------|--------|------------------|------------------|
| 1.00e-02 | 1.000000e-02 | 8.881784e-16 | 1.0    | 0.99 | 1.0 |
| 1.00e-04 | 1.000000e-04 | 1.101341e-13 | 1.0    | 0.9999 | 1.0 |
| 1.00e-06 | 9.999177e-07 | 2.675549e-11 | 1.0    | 0.999999 | 1.0 |
| 1.00e-08 | 3.922529e-09 | 5.263561e-10 | 1.0    | 0.999999996 | 1.0 |
| 1.00e-10 | 8.284037e-08 | 8.274037e-08 | 1.0    | 0.00008284 | 0.00008274 |
| 1.00e-12 | 8.890058e-05 | 3.338943e-05 | 1.0    | 0.0000889 | 0.00003339 |
| 1.00e-14 | 7.992778e-04 | 7.992778e-04 | 1.0    | 0.00079928 | 0.00079928 |

### 3.2 误差-步长关系图
（在此插入误差-步长关系图，并简要说明图中观察到的现象）
![1](https://github.com/user-attachments/assets/8275611a-0118-4f6d-9b1d-0b5eadba94ae)


## 4. 分析与讨论
### 4.1 误差来源分析
数值微分中存在两种主要误差来源：
- **截断误差**：由于使用有限差分近似导数定义引入的误差，通常随步长减小而减小
- **舍入误差**：由于计算机浮点数表示的有限精度引入的误差，通常随步长减小而增大

（分析实验中观察到的截断误差和舍入误差的表现）

### 4.2 前向差分与中心差分的比较
（比较两种方法的精度差异，并解释原因）
中心差分法的精度总体上高于前向差分法。原因在于中心差分公式是二阶精度的，其截断误差是  O(\Delta x^2) ；而前向差分公式是一阶精度的，截断误差是  O(\Delta x) 。这使得中心差分在相同步长下能更精确地逼近导数。

### 4.3 最优步长分析
（分析实验中观察到的最优步长，并解释为什么存在最优步长）
实验观察到前向差分和中心差分都存在最优步长。对于前向差分，最优步长在  10^{-8}  左右；对于中心差分，最优步长在  10^{-10}  左右。存在最优步长是因为截断误差和舍入误差的相互作用：步长减小，截断误差减小但舍入误差增大；步长增大，舍入误差减小但截断误差增大，在两者平衡处即为最优步长。

### 4.4 收敛阶数分析
（分析两种方法的收敛阶数，并与理论预期进行比较）
通过对误差 - 步长关系图中误差曲线的斜率分析，前向差分法的收敛阶数接近 1，中心差分法的收敛阶数接近 2，这与理论预期相符，即前向差分是一阶收敛，中心差分是二阶收敛。

## 5. 实验结论
（总结本实验的主要发现，特别是关于误差权衡、最优步长和不同差分方法的优缺点）
本实验通过Python编程实现了前向差分法和中心差分法计算数值导数，并分析了误差特性。主要发现如下：
 
- 数值微分中的截断误差和舍入误差相互权衡，共同影响计算精度。
 
- 中心差分法精度高于前向差分法，因其具有更高的收敛阶数。
 
- 存在最优步长，在该步长下误差最小，此时截断误差和舍入误差达到较好的平衡。
 
在实际应用中，应根据具体需求选择合适的差分方法和步长，以提高数值微分计算的精度。

## 附录：核心代码片段
```python
# 前向差分法实现
def forward_diff(f, x, delta):
    return (f(x + delta) - f(x)) / delta

# 中心差分法实现
def central_diff(f, x, delta):
    return (f(x + delta) - f(x - delta)) / (2 * delta)

# 计算误差的代码
def calculate_errors(x_point=1.0):
    deltas = np.logspace(-2, -14, 7)
        true_value = analytical_derivative(x_point)
        forward_errors = []
        central_errors = []
        for delta in deltas:
            forward_value = forward_diff(f, x_point, delta)
            forward_rel_error = abs((forward_value - true_value) / true_value)
            forward_errors.append(forward_rel_error)
            central_value = central_diff(f, x_point, delta)
            central_rel_error = abs((central_value - true_value) / true_value)
            central_errors.append(central_rel_error)
        return deltas, forward_errors,central_errors

# 绘制误差-步长关系图的代码
def plot_errors(deltas, forward_errors, central_errors):
    plt.figure(figsize=(10, 6))
    plt.loglog(deltas, forward_errors, 'o-', label='Forward Difference')        # 绘制中心差分误差    
    plt.loglog(deltas, central_errors, 's-', label='Central Difference')
    plt.loglog(deltas, deltas, '--', label='First Order O(h)')    
    plt.loglog(deltas, np.array(deltas)**2, '--', label='Second Order O($h^2$)')
    plt.xlabel('Step Size $\\delta$')  # Fixed escape sequence    
    plt.ylabel('Relative Error')    
    plt.title('Error vs Step Size in Numerical Differentiation')    
    plt.grid(True, which="both", ls="-")
    plt.legend()
    plt.savefig('error_vs_stepsize.png', dpi=300)
    plt.show()
#打印计算结果表格的代码
def print_results(deltas, forward_errors, central_errors):
    print("步长(δ)\t前向差分误差\t中心差分误差")
        print("-" * 50)
        for i in range(len(deltas)):
            print(f"{deltas[i]:.2e}\t{forward_errors[i]:.6e}\t{central_errors[i]:.6e}")

